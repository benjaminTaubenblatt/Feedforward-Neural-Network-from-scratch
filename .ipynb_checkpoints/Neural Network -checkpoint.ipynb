{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes random splits in dataset, labels for train and valid sets\n",
    "# Example: X_train, y_train, X_valid, y_valid = train_valid_split(train_images.values, train_labels.values, 0.8, 0.2)\n",
    "def train_valid_split(dataset, labels, train_split, valid_split):\n",
    "    if (train_split + valid_split) != 1:\n",
    "        raise ValueError(\"invalid size for train_split, valid_split\")\n",
    "    num_rows = dataset.shape[0]\n",
    "    num_cols = dataset.shape[1]\n",
    "    train = list()\n",
    "    valid = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    \n",
    "    y_train = list()\n",
    "    y_valid = list()\n",
    "    labels_copy = list(labels)\n",
    "    \n",
    "    train_size = train_split*num_rows\n",
    "    valid_size = valid_split*num_rows\n",
    "    \n",
    "    while len(train) < train_size:\n",
    "        index = random.randrange(len(dataset_copy))\n",
    "        train.append(dataset_copy.pop(index))\n",
    "        y_train.append(labels_copy.pop(index))\n",
    "    \n",
    "    while len(valid) < valid_size:\n",
    "        index = random.randrange(len(dataset_copy))\n",
    "        valid.append(dataset_copy.pop(index))\n",
    "        y_valid.append(labels_copy.pop(index))\n",
    "        \n",
    "    return pd.DataFrame(np.array(train)), pd.DataFrame(np.array(y_train)),pd.DataFrame(np.array(valid)),pd.DataFrame(np.array(y_valid))\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(data):\n",
    "    new_data = np.zeros((data.shape[0],data.shape[1]))\n",
    "    for i in range(data.shape[1]):\n",
    "        a_col = data[:,i]\n",
    "        col_mean = np.mean(a_col)\n",
    "        col_std = np.std(a_col)\n",
    "        if col_std != 0.0:\n",
    "            data[:,i]-col_mean/col_std\n",
    "    return new_data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuronLayer():\n",
    "    def __init__(self, num_neurons, num_inputs_per_neuron):\n",
    "        self.weights = 2 * np.random.random((num_inputs_per_neuron,num_neurons)) - 1        \n",
    "    \n",
    "class NeuralNetwork: \n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        self.bias = 0.0 #np.random.rand(1)  \n",
    "        \n",
    "    \n",
    "    def activate(self, fn, x, deriv=False):\n",
    "        if fn == 'sigmoid':\n",
    "            if deriv:\n",
    "                return x*(1-x)\n",
    "            else:\n",
    "                return 1/(1+np.exp(-x))\n",
    "        elif fn == 'softmax':\n",
    "            result = np.exp(x[0] - np.max(x[0]))\n",
    "            e1_sum = np.sum(result)\n",
    "            if e1_sum != 0.0:\n",
    "                result = result/e1_sum\n",
    "\n",
    "            for i in range(1, x.shape[0]):\n",
    "                e = np.exp(x[i] - np.max(x[i]))\n",
    "                e_sum = np.sum(e)\n",
    "                if e_sum != 0.0:\n",
    "                    new_row = e/e_sum\n",
    "                    result = np.vstack((result, new_row))\n",
    "                else:\n",
    "                    result = np.vstack((result, e))\n",
    "\n",
    "            return result\n",
    "        else:\n",
    "            raise ValueError('fn attribute must be one of: [ sigmoid, softmax ]')\n",
    "            \n",
    "    def feed_forward(self, inp, layers, outputs, fn):\n",
    "        if layers == []:\n",
    "            return inp, outputs\n",
    "        xW = np.dot(inp, layers.pop(0).weights) + self.bias\n",
    "        z = self.activate(fn, xW)\n",
    "        outputs.append(z)\n",
    "        return self.feed_forward(z, layers, outputs, fn)\n",
    "    \n",
    "    def backpropagation(self, error, outputs, layers, fn):\n",
    "        if outputs == []:\n",
    "            return []\n",
    "        \n",
    "        output_H = outputs.pop(-1) #Oj\n",
    "        dzO_dwO = self.activate(fn, output_H, deriv=True) #Oj_prime\n",
    "        o_delta = error*dzO_dwO #delta\n",
    "        new_error = o_delta.dot(layers.pop(-1).weights.T) #error for next layer\n",
    "        \n",
    "        return  self.backpropagation(new_error, outputs, layers, fn) + [o_delta]\n",
    "\n",
    "    \n",
    "    def one_hot_encoding(self, X, y, num_classes):\n",
    "        ohl = np.zeros((X.shape[0], num_classes))\n",
    "        for i in range(X.shape[0]):\n",
    "            ohl[i, int(y[i,0])] = 1\n",
    "        return ohl\n",
    "    \n",
    "    def stochastic_gradient_descent(self, x, y_single, alpha, epoch_size, fn, num_classes, show_error=1000):\n",
    "        y = self.one_hot_encoding(x, y_single, num_classes)\n",
    "        for i in range(epoch_size):\n",
    "            \n",
    "            yhat, all_outputs = self.feed_forward(x, list(self.layers), [], 'sigmoid')\n",
    "            \n",
    "            err = (self.activate('softmax', yhat) - y)\n",
    "            err_sqrd = np.square(err)\n",
    "            err_deriv = 2*err\n",
    "            \n",
    "            if i%show_error == 0:\n",
    "                print('Epoch: %s' % i)\n",
    "                print (\"\\tError:\" + str(round(np.mean(np.abs(err_sqrd)), 5)))\n",
    "                \n",
    "            deltas = self.backpropagation(err_deriv, list(all_outputs), list(self.layers), fn)\n",
    "            update_values = [x] + all_outputs\n",
    "            for k,v in enumerate(self.layers):\n",
    "                v.weights -= np.dot(update_values[k].T, deltas[k])*alpha\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_score(nn, x_ts, y_ts):\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    yhat, output = nn.feed_forward(x_ts, list(nn.layers), [], 'sigmoid')\n",
    "    yhat_soft = nn.activate('softmax', yhat)\n",
    "    all_pred = []\n",
    "    for i,v in enumerate(yhat_soft):\n",
    "        pred = np.argmax(v)\n",
    "        all_pred.append(pred)\n",
    "    print(round(accuracy_score(y_ts.values.ravel(),all_pred), 2))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from matplotlib import pyplot\n",
    "\n",
    "X, y_raw = make_moons(n_samples=100, noise=0.05)\n",
    "y = y_raw.reshape(-1,1)\n",
    "X_tr, y_tr, X_vl, y_vl = train_valid_split(X,y,0.8,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\tError:0.25336\n",
      "Epoch: 5000\n",
      "\tError:0.12835\n",
      "Epoch: 10000\n",
      "\tError:0.12584\n",
      "Epoch: 15000\n",
      "\tError:0.12499\n"
     ]
    }
   ],
   "source": [
    "l1 = NeuronLayer(4,2)\n",
    "l2 = NeuronLayer(3,4)\n",
    "l3 = NeuronLayer(2,3)\n",
    "fnn = NeuralNetwork([l1, l2, l3])\n",
    "\n",
    "fnn.stochastic_gradient_descent(X_tr.values, y_tr.values, 0.01, 20000, 'sigmoid', 2, show_error=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n"
     ]
    }
   ],
   "source": [
    "predict_and_score(fnn, X_vl.values, y_vl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
